{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb22b94-4641-4917-b787-bf9ed4cdcc90",
   "metadata": {},
   "source": [
    "### All packages needed for original implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de0ccf0-8942-4e79-837c-ba59ee336dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0300341c-9d67-4f5f-a69f-1cbfe0de46d5",
   "metadata": {},
   "source": [
    "## Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6ee918-43fb-4f21-9f63-150e9a8fce9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a12557-67de-4416-9fb2-b13148e68ff2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pinned Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814ad182-1b8e-433a-bbfa-be4a61fc76a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_tf = Compose([ToTensor(), Normalize((0.1307,), (0.3081,)),\n",
    "                   Lambda(torch.flatten)])\n",
    "\n",
    "orig_train_kwargs = {'batch_size': 50000}\n",
    "orig_test_kwargs = {'batch_size': 10000}\n",
    "if device == 'cuda':\n",
    "    orig_cuda_kwargs = {'num_workers': 1, 'shuffle': True, 'pin_memory': True}\n",
    "    orig_train_kwargs.update(orig_cuda_kwargs)\n",
    "    orig_test_kwargs.update(orig_cuda_kwargs)\n",
    "\n",
    "orig_train_loader = DataLoader(\n",
    "    MNIST('./data/', train=True, download=True, transform=orig_tf), **orig_train_kwargs\n",
    ")\n",
    "\n",
    "orig_test_loader = DataLoader( # may be unnecessary\n",
    "    MNIST('./data/', train=False, download=True, transform=orig_tf), **orig_test_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f60f5-b0db-4633-ad28-c6678bbc27b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Unpinned Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6fd5ec-47d6-4f73-ae31-692bd82e2526",
   "metadata": {},
   "source": [
    "#### 1 sub-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9fd298e5-4c64-452d-ae4c-5c91343e6201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_tf = Compose([ToTensor(), Normalize((0.1307,), (0.3081,)),\n",
    "                   Lambda(torch.flatten)])\n",
    "\n",
    "orig_train_kwargs = {'batch_size': 50000}\n",
    "orig_test_kwargs = {'batch_size': 10000}\n",
    "if device == 'cuda':\n",
    "    orig_cuda_kwargs = {'num_workers': 1, 'shuffle': True, 'pin_memory': False}\n",
    "    orig_train_kwargs.update(orig_cuda_kwargs)\n",
    "    orig_test_kwargs.update(orig_cuda_kwargs)\n",
    "\n",
    "orig_train_loader = DataLoader(\n",
    "    MNIST('./data/', train=True, download=True, transform=orig_tf), **orig_train_kwargs\n",
    ")\n",
    "\n",
    "orig_test_loader = DataLoader( # may be unnecessary\n",
    "    MNIST('./data/', train=False, download=True, transform=orig_tf), **orig_test_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fca43-ba1c-4017-a788-33472dcf58be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reconstructing Original Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f6840751-e5c8-448a-bdae-cd320a6c20f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label(x, y, n_labels=10):\n",
    "    out = x.clone()\n",
    "    out[:, :n_labels] *= 0.0\n",
    "    out[range(x.shape[0]), y] = x.max()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "312b9d5e-a38b-445c-8577-aeb86265c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrigLayer(nn.Linear):\n",
    "    def __init__(self, f_in, f_out, bias=True, device=None, dtype=None,\n",
    "                threshold=2., num_epochs=60):\n",
    "        super().__init__(f_in, f_out, bias, device, dtype)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.opt = Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = threshold\n",
    "        self.num_epochs = num_epochs\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4) # not sure what the point of this is, but it looks kind of like LVQ\n",
    "        # norm yields L2 norm of abs(x): sum(abs(x)**2)**(1/2); 2 can be replaced by any number using 1st arg\n",
    "        # using 'fro' as first arg gives L2 norm of x\n",
    "        # using 'nuc' gives nuclear norm of x: sum(root2(e_i)) for eigenvalues E of X' @ X or X @ X'\n",
    "        \n",
    "        return self.relu(torch.mm(x_direction, self.weight.T) + self.bias.unsqueeze(0)) # X_dir @ W' + b\n",
    "    \n",
    "    def train(self, x_pos, x_neg):\n",
    "        for i in range(self.num_epochs):\n",
    "            # for each image, obtain average of squared activations\n",
    "            g_pos = self.forward(x_pos).pow(2).mean(1)\n",
    "            g_neg = self.forward(x_neg).pow(2).mean(1)\n",
    "            \n",
    "            # for each image, loss = ln(1 + e^(wrongness))\n",
    "            # for negative wrongness = positive/negative(goodness - threshold)\n",
    "            loss = torch.log1p(torch.exp(\n",
    "                torch.cat([self.threshold - g_pos, g_neg - self.threshold])\n",
    "            )).mean()\n",
    "            \n",
    "            self.opt.zero_grad() # reset gradient to 0\n",
    "            loss.backward() # calculate gradient - not backpropagation because nothing to propagate to\n",
    "            self.opt.step() # adjust weights according to Adam optimizer: gradient descent with global, local momentum\n",
    "            if i % log_interval == 0:\n",
    "                print('Loss: ', loss.item())\n",
    "                \n",
    "        self.opt.zero_grad() # to save memory        \n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach() # send to next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d9b5fabb-567b-40c6-adad-17147d481990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OrigNet(torch.nn.Module):\n",
    "    def __init__(self, dims, num_epochs=60, pos_labels=10):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for d in range(len(dims) - 1):\n",
    "            self.layers = self.layers + [OrigLayer(dims[d], dims[d+1], num_epochs=num_epochs).to(device)]\n",
    "        \n",
    "        if type(pos_labels) == int:\n",
    "            self.labels = range(pos_labels)\n",
    "            self.n_label = pos_labels\n",
    "        else:\n",
    "            raise TypeError('parameter pos_labels must be of type Int')\n",
    "    \n",
    "    def predict(self, x):\n",
    "        goodness_per_label = []\n",
    "        for l in self.labels:\n",
    "            h = label(x, l, self.n_label)\n",
    "            goodness = []\n",
    "            \n",
    "            for layer in self.layers:\n",
    "                h = layer(h)\n",
    "                goodness = goodness + [h.pow(2).mean(1)]\n",
    "            goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
    "        \n",
    "        goodness_per_label = torch.cat(goodness_per_label, 1)\n",
    "        return goodness_per_label.argmax(1)\n",
    "    \n",
    "    def train(self, x_pos, x_neg):\n",
    "        h_pos, h_neg = x_pos, x_neg\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print('training layer: ', i)\n",
    "            h_pos, h_neg = layer.train(h_pos, h_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4b496ebf-5b1e-4798-809d-c5643475c214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neg(x, y, n_labels=10, ratio=1): # constructed myself\n",
    "    labels = []\n",
    "    for n in range(n_labels):\n",
    "        labels.append(n)\n",
    "        \n",
    "    y_neg = []\n",
    "    for n in range(ratio):\n",
    "        y_neg.append(torch.zeros_like(y))\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        labels_ = labels.copy()\n",
    "        labels_.remove(y[i])\n",
    "        negs = random.sample(labels_, k=ratio)\n",
    "        for n in range(len(negs)):\n",
    "            y_neg[n][i] = negs[n]\n",
    "            \n",
    "    x_neg = []\n",
    "    for yn in y_neg:\n",
    "        x_neg.append(label(x, yn, n_labels))\n",
    "    x_neg = torch.cat(x_neg)\n",
    "    return x_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17f1e1f8-3256-444a-9a01-1b4a70d07665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aa15362b-8f5c-41fe-98dc-f2460793a52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a, b = orig_train_loader\n",
    "x, y = a\n",
    "x, y = x.to(device), y.to(device)\n",
    "\n",
    "x_val, y_val = b\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "69f392de-8130-4db9-b6ca-2e146e51f90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_pos = label(x, y)\n",
    "x_neg = get_neg(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4bea2b7-7f5a-4cb4-8ac2-c9441fc4b0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_builtin_training(net, x_pos, x_neg, y_train, x_val, y_val):\n",
    "    net.train(x_pos, x_neg)\n",
    "    print('train error:', 1 - net.predict(x).eq(y_train).float().mean().item())\n",
    "    print('valid error:', 1 - net.predict(x_val).eq(y_val).float().mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432187d-ec14-490a-a498-6b93349cab20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Simplified version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e9f6c-6c7d-49c5-b213-4159a7a99a0a",
   "metadata": {},
   "source": [
    "2 hidden layers, 500 ReLUs each, as in GitHub implementation. Trained for 60 epochs as in paper, and for 1000 epochs as in GitHub implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "29854cc3-e677-47e5-8b5b-0483c6372ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_short = OrigNet([784, 500, 500])\n",
    "orig_full = OrigNet([784, 500, 500], num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1fa924e3-7ec5-471c-9da8-e6e9cbd69b45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer:  0\n",
      "Loss:  1.1267759799957275\n",
      "Loss:  0.7555526494979858\n",
      "Loss:  0.7025285959243774\n",
      "Loss:  0.7051083445549011\n",
      "Loss:  0.6946920156478882\n",
      "Loss:  0.6919478178024292\n",
      "training layer:  1\n",
      "Loss:  1.126697301864624\n",
      "Loss:  0.7611115574836731\n",
      "Loss:  0.7094106078147888\n",
      "Loss:  0.6954320669174194\n",
      "Loss:  0.6950199604034424\n",
      "Loss:  0.6949039697647095\n",
      "train error: 0.8863399997353554\n",
      "valid error: 0.8941000029444695\n"
     ]
    }
   ],
   "source": [
    "run_builtin_training(orig_short, x_pos, x_neg, y, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "35bbd0cf-5f9f-49c0-a446-dba4aeb799c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer:  0\n",
      "Loss:  1.1267536878585815\n",
      "Loss:  0.7554960250854492\n",
      "Loss:  0.7023795247077942\n",
      "Loss:  0.7050467133522034\n",
      "Loss:  0.6946635842323303\n",
      "Loss:  0.6918877959251404\n",
      "Loss:  0.6902346611022949\n",
      "Loss:  0.6880416870117188\n",
      "Loss:  0.6850091814994812\n",
      "Loss:  0.6807626485824585\n",
      "Loss:  0.6750123500823975\n",
      "Loss:  0.6676493287086487\n",
      "Loss:  0.6587328910827637\n",
      "Loss:  0.6485069990158081\n",
      "Loss:  0.6374150514602661\n",
      "Loss:  0.6259715557098389\n",
      "Loss:  0.6145788431167603\n",
      "Loss:  0.6034327745437622\n",
      "Loss:  0.5925993323326111\n",
      "Loss:  0.5820996761322021\n",
      "Loss:  0.5719447731971741\n",
      "Loss:  0.5621438026428223\n",
      "Loss:  0.5526914596557617\n",
      "Loss:  0.5435778498649597\n",
      "Loss:  0.5347889065742493\n",
      "Loss:  0.526311457157135\n",
      "Loss:  0.518135666847229\n",
      "Loss:  0.5102538466453552\n",
      "Loss:  0.5026540756225586\n",
      "Loss:  0.4953247010707855\n",
      "Loss:  0.48825550079345703\n",
      "Loss:  0.48143601417541504\n",
      "Loss:  0.4748579263687134\n",
      "Loss:  0.4685148596763611\n",
      "Loss:  0.46240001916885376\n",
      "Loss:  0.4565066397190094\n",
      "Loss:  0.45082592964172363\n",
      "Loss:  0.44534698128700256\n",
      "Loss:  0.4400603771209717\n",
      "Loss:  0.43495869636535645\n",
      "Loss:  0.4300346076488495\n",
      "Loss:  0.42527952790260315\n",
      "Loss:  0.42068448662757874\n",
      "Loss:  0.416240394115448\n",
      "Loss:  0.41193896532058716\n",
      "Loss:  0.4077729284763336\n",
      "Loss:  0.4037362337112427\n",
      "Loss:  0.3998226523399353\n",
      "Loss:  0.3960254490375519\n",
      "Loss:  0.39233893156051636\n",
      "Loss:  0.3887585699558258\n",
      "Loss:  0.38528013229370117\n",
      "Loss:  0.38189905881881714\n",
      "Loss:  0.378610759973526\n",
      "Loss:  0.3754110038280487\n",
      "Loss:  0.372295618057251\n",
      "Loss:  0.3692611753940582\n",
      "Loss:  0.36630409955978394\n",
      "Loss:  0.3634207248687744\n",
      "Loss:  0.3606072664260864\n",
      "Loss:  0.35786014795303345\n",
      "Loss:  0.3551764488220215\n",
      "Loss:  0.35255351662635803\n",
      "Loss:  0.3499884307384491\n",
      "Loss:  0.3474787771701813\n",
      "Loss:  0.3450221121311188\n",
      "Loss:  0.342616468667984\n",
      "Loss:  0.34026017785072327\n",
      "Loss:  0.33795177936553955\n",
      "Loss:  0.3356897532939911\n",
      "Loss:  0.33347249031066895\n",
      "Loss:  0.3312986195087433\n",
      "Loss:  0.3291665017604828\n",
      "Loss:  0.32707443833351135\n",
      "Loss:  0.3250206410884857\n",
      "Loss:  0.32300350069999695\n",
      "Loss:  0.3210214078426361\n",
      "Loss:  0.31907275319099426\n",
      "Loss:  0.31715598702430725\n",
      "Loss:  0.31526944041252136\n",
      "Loss:  0.313411682844162\n",
      "Loss:  0.3115813434123993\n",
      "Loss:  0.309777170419693\n",
      "Loss:  0.3079981207847595\n",
      "Loss:  0.306243360042572\n",
      "Loss:  0.3045122027397156\n",
      "Loss:  0.3028039038181305\n",
      "Loss:  0.301117867231369\n",
      "Loss:  0.29945361614227295\n",
      "Loss:  0.29781073331832886\n",
      "Loss:  0.2961885333061218\n",
      "Loss:  0.2945860028266907\n",
      "Loss:  0.29300200939178467\n",
      "Loss:  0.2914353907108307\n",
      "Loss:  0.2898850440979004\n",
      "Loss:  0.2883499264717102\n",
      "Loss:  0.286828875541687\n",
      "Loss:  0.28532108664512634\n",
      "Loss:  0.28382593393325806\n",
      "Loss:  0.2823430299758911\n",
      "training layer:  1\n",
      "Loss:  1.1266460418701172\n",
      "Loss:  0.6302976608276367\n",
      "Loss:  0.5492945313453674\n",
      "Loss:  0.5367873907089233\n",
      "Loss:  0.5313780903816223\n",
      "Loss:  0.5201224088668823\n",
      "Loss:  0.5118009448051453\n",
      "Loss:  0.501055896282196\n",
      "Loss:  0.48794999718666077\n",
      "Loss:  0.47255975008010864\n",
      "Loss:  0.45620453357696533\n",
      "Loss:  0.43998897075653076\n",
      "Loss:  0.42489612102508545\n",
      "Loss:  0.4112774133682251\n",
      "Loss:  0.399189293384552\n",
      "Loss:  0.38845890760421753\n",
      "Loss:  0.3789377212524414\n",
      "Loss:  0.3704390823841095\n",
      "Loss:  0.3627870976924896\n",
      "Loss:  0.3558630347251892\n",
      "Loss:  0.34955474734306335\n",
      "Loss:  0.3437679708003998\n",
      "Loss:  0.338417649269104\n",
      "Loss:  0.3334290683269501\n",
      "Loss:  0.32876506447792053\n",
      "Loss:  0.3243837356567383\n",
      "Loss:  0.3202386498451233\n",
      "Loss:  0.31629636883735657\n",
      "Loss:  0.3125480115413666\n",
      "Loss:  0.30898383259773254\n",
      "Loss:  0.3055955469608307\n",
      "Loss:  0.3023659288883209\n",
      "Loss:  0.2992761433124542\n",
      "Loss:  0.2963111400604248\n",
      "Loss:  0.29346370697021484\n",
      "Loss:  0.2907259166240692\n",
      "Loss:  0.2880873382091522\n",
      "Loss:  0.2855382263660431\n",
      "Loss:  0.28307148814201355\n",
      "Loss:  0.2806786000728607\n",
      "Loss:  0.27834996581077576\n",
      "Loss:  0.27607956528663635\n",
      "Loss:  0.2738669514656067\n",
      "Loss:  0.27171310782432556\n",
      "Loss:  0.2696171700954437\n",
      "Loss:  0.26757577061653137\n",
      "Loss:  0.26558539271354675\n",
      "Loss:  0.2636431157588959\n",
      "Loss:  0.26174572110176086\n",
      "Loss:  0.25988873839378357\n",
      "Loss:  0.25806811451911926\n",
      "Loss:  0.2562825381755829\n",
      "Loss:  0.2545316517353058\n",
      "Loss:  0.25281602144241333\n",
      "Loss:  0.2511362135410309\n",
      "Loss:  0.24949218332767487\n",
      "Loss:  0.24788281321525574\n",
      "Loss:  0.24630706012248993\n",
      "Loss:  0.24476437270641327\n",
      "Loss:  0.243254616856575\n",
      "Loss:  0.24177779257297516\n",
      "Loss:  0.24033315479755402\n",
      "Loss:  0.23891982436180115\n",
      "Loss:  0.2375364601612091\n",
      "Loss:  0.23618167638778687\n",
      "Loss:  0.23485451936721802\n",
      "Loss:  0.23355533182621002\n",
      "Loss:  0.23228438198566437\n",
      "Loss:  0.23104098439216614\n",
      "Loss:  0.229824036359787\n",
      "Loss:  0.2286321073770523\n",
      "Loss:  0.22746339440345764\n",
      "Loss:  0.22631603479385376\n",
      "Loss:  0.2251894325017929\n",
      "Loss:  0.22408409416675568\n",
      "Loss:  0.22299997508525848\n",
      "Loss:  0.22193652391433716\n",
      "Loss:  0.22089296579360962\n",
      "Loss:  0.21986855566501617\n",
      "Loss:  0.21886228024959564\n",
      "Loss:  0.21787303686141968\n",
      "Loss:  0.21689929068088531\n",
      "Loss:  0.21593882143497467\n",
      "Loss:  0.21498948335647583\n",
      "Loss:  0.21405139565467834\n",
      "Loss:  0.2131267488002777\n",
      "Loss:  0.21221725642681122\n",
      "Loss:  0.21132329106330872\n",
      "Loss:  0.2104448825120926\n",
      "Loss:  0.20958183705806732\n",
      "Loss:  0.20873373746871948\n",
      "Loss:  0.20790016651153564\n",
      "Loss:  0.20708058774471283\n",
      "Loss:  0.20627440512180328\n",
      "Loss:  0.20548094809055328\n",
      "Loss:  0.2046995609998703\n",
      "Loss:  0.20392921566963196\n",
      "Loss:  0.2031688094139099\n",
      "Loss:  0.2024175524711609\n",
      "Loss:  0.2016749382019043\n",
      "train error: 0.07330000400543213\n",
      "valid error: 0.07700002193450928\n"
     ]
    }
   ],
   "source": [
    "run_builtin_training(orig_full, x_pos, x_neg, y, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a14ae-1281-4f37-8d7d-68ea4ffc8987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf85bb8c-ed36-49e0-9e75-7204c5da3d3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Full Version\n",
    "4 hidden layers, 500 ReLUs each, full connectivity.  \n",
    "Ran out of memory on my machine, so trying on school computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "581b74c0-0907-42e7-8e77-421bb450cf37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_net = OrigNet([784, 2000, 2000, 2000, 2000], num_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2794b557-b453-49cf-b081-c9004c627d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer:  0\n",
      "Loss:  1.126765251159668\n",
      "Loss:  0.7479006052017212\n",
      "Loss:  0.7062171101570129\n",
      "Loss:  0.7044826149940491\n",
      "Loss:  0.6943631172180176\n",
      "Loss:  0.6927698254585266\n",
      "training layer:  1\n",
      "Loss:  1.126866340637207\n",
      "Loss:  0.7166959047317505\n",
      "Loss:  0.7191349267959595\n",
      "Loss:  0.7072288393974304\n",
      "Loss:  0.6964314579963684\n",
      "Loss:  0.6948375105857849\n",
      "training layer:  2\n",
      "Loss:  1.1268635988235474\n",
      "Loss:  0.698647141456604\n",
      "Loss:  0.6934477686882019\n",
      "Loss:  0.6957640647888184\n",
      "Loss:  0.6956759691238403\n",
      "Loss:  0.6932473182678223\n",
      "training layer:  3\n",
      "Loss:  1.1268658638000488\n",
      "Loss:  0.6932251453399658\n",
      "Loss:  0.6981924176216125\n",
      "Loss:  0.6991353034973145\n",
      "Loss:  0.6945857405662537\n",
      "Loss:  0.6933739185333252\n"
     ]
    }
   ],
   "source": [
    "full_net.train(x_pos, x_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55f82218-aea5-40a9-9d39-5c1d70ac7e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer:  0\n",
      "Loss:  1.1267642974853516\n",
      "Loss:  0.7487234473228455\n",
      "Loss:  0.7057836055755615\n",
      "Loss:  0.7045142650604248\n",
      "Loss:  0.6942316293716431\n",
      "Loss:  0.6925638914108276\n",
      "training layer:  1\n",
      "Loss:  1.1268638372421265\n",
      "Loss:  0.7584021687507629\n",
      "Loss:  0.7163705229759216\n",
      "Loss:  0.6950255036354065\n",
      "Loss:  0.6974285840988159\n",
      "Loss:  0.6946664452552795\n",
      "training layer:  2\n",
      "Loss:  1.126861333847046\n",
      "Loss:  0.6975537538528442\n",
      "Loss:  0.6938495635986328\n",
      "Loss:  0.6964575052261353\n",
      "Loss:  0.6956017017364502\n",
      "Loss:  0.6931670904159546\n",
      "training layer:  3\n",
      "Loss:  1.1268620491027832\n",
      "Loss:  0.6931763887405396\n",
      "Loss:  0.6979731917381287\n",
      "Loss:  0.6991063952445984\n",
      "Loss:  0.6949303150177002\n",
      "Loss:  0.6932732462882996\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 4.00 GiB total capacity; 10.08 GiB already allocated; 0 bytes free; 10.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_builtin_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_neg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m, in \u001b[0;36mrun_builtin_training\u001b[1;34m(net, x_pos, x_neg, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_builtin_training\u001b[39m(net, x_pos, x_neg, y_train, x_val, y_val):\n\u001b[0;32m      2\u001b[0m     net\u001b[38;5;241m.\u001b[39mtrain(x_pos, x_neg)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain error:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meq(y_train)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid error:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(x_val)\u001b[38;5;241m.\u001b[39meq(y_val)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m, in \u001b[0;36mOrigNet.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m goodness \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 21\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     goodness \u001b[38;5;241m=\u001b[39m goodness \u001b[38;5;241m+\u001b[39m [h\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     23\u001b[0m goodness_per_label \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(goodness)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\compatibility\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36mOrigLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 11\u001b[0m     x_direction \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# not sure what the point of this is, but it looks kind of like LVQ\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# norm yields L2 norm of abs(x): sum(abs(x)**2)**(1/2); 2 can be replaced by any number using 1st arg\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# using 'fro' as first arg gives L2 norm of x\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# using 'nuc' gives nuclear norm of x: sum(root2(e_i)) for eigenvalues E of X' @ X or X @ X'\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(torch\u001b[38;5;241m.\u001b[39mmm(x_direction, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 4.00 GiB total capacity; 10.08 GiB already allocated; 0 bytes free; 10.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "run_builtin_training(full_net, x_pos, x_neg, y, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e6648cc-bcf4-44da-b9ae-3ca514747a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer:  0\n",
      "Loss:  1.1267696619033813\n",
      "Loss:  0.7488387227058411\n",
      "Loss:  0.7057278156280518\n",
      "Loss:  0.7045210003852844\n",
      "Loss:  0.6941994428634644\n",
      "Loss:  0.6924904584884644\n",
      "training layer:  1\n",
      "Loss:  1.126865267753601\n",
      "Loss:  0.7594606280326843\n",
      "Loss:  0.7137991786003113\n",
      "Loss:  0.6947801113128662\n",
      "Loss:  0.6979151964187622\n",
      "Loss:  0.6945226192474365\n",
      "training layer:  2\n",
      "Loss:  1.1268651485443115\n",
      "Loss:  0.6990825533866882\n",
      "Loss:  0.6933636665344238\n",
      "Loss:  0.6956015229225159\n",
      "Loss:  0.6956831812858582\n",
      "Loss:  0.6932703852653503\n",
      "training layer:  3\n",
      "Loss:  1.1268653869628906\n",
      "Loss:  0.6935575604438782\n",
      "Loss:  0.6974059343338013\n",
      "Loss:  0.6988356113433838\n",
      "Loss:  0.6946021914482117\n",
      "Loss:  0.6933574676513672\n"
     ]
    }
   ],
   "source": [
    "full_net.train(x_pos, x_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63faa37f-fbdd-4501-b8bb-541ab707a527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_net = full_net.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1946acd7-42f1-4852-8c0b-f2213c7f46a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_x = x.to('cpu')\n",
    "temp_y = y.to('cpu')\n",
    "temp_x_val = x_val.to('cpu')\n",
    "temp_y_val = y_val.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5e306-505c-4052-854f-cbacd9875f57",
   "metadata": {},
   "source": [
    "## Batch Training Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9ee6f-950b-4e7d-b9af-dbfae69ca2ac",
   "metadata": {},
   "source": [
    "Mainly trying to avoid CUDA out-of-memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c39ea4-e3a5-4177-8796-8c63ee9e3c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pin_memory = False\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b0ba13-bce6-4469-bf43-29aca366957f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_tf = Compose([ToTensor(), Normalize((0.1307), (0.3081)), Lambda(torch.flatten)])\n",
    "\n",
    "train_valid_kwargs = {'batch_size': 256}\n",
    "test_kwargs = {'batch_size': 10000}\n",
    "if device == 'cuda':\n",
    "    cuda_kwargs = {'num_workers': num_workers, 'pin_memory': pin_memory, 'shuffle': False}\n",
    "    train_valid_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "train_valid_loader = DataLoader(\n",
    "    MNIST('./data/', train=True, download=True, transform=orig_tf), **train_valid_kwargs\n",
    ")\n",
    "\n",
    "orig_test_loader = DataLoader(\n",
    "    MNIST('./data/', train=False, download=True, transform=orig_tf), **test_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea5221a-e9db-4010-84c1-657b2c188aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label(x, y, n_labels=10):\n",
    "    out = x.clone()\n",
    "    out[:, :n_labels] *= 0.0\n",
    "    out[range(x.shape[0]), y] = x.max()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d325b6-2be1-44dc-a280-2fa6bf53c2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neg(x, y, n_labels=10, ratio=1): # constructed myself\n",
    "    labels = []\n",
    "    for n in range(n_labels):\n",
    "        labels.append(n)\n",
    "        \n",
    "    y_neg = []\n",
    "    for n in range(ratio):\n",
    "        y_neg.append(torch.zeros_like(y))\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        labels_ = labels.copy()\n",
    "        labels_.remove(y[i])\n",
    "        negs = random.sample(labels_, k=ratio)\n",
    "        for n in range(len(negs)):\n",
    "            y_neg[n][i] = negs[n]\n",
    "            \n",
    "    x_neg = []\n",
    "    for yn in y_neg:\n",
    "        x_neg.append(label(x, yn, n_labels))\n",
    "    x_neg = torch.cat(x_neg)\n",
    "    return x_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033895bf-d443-49b3-9233-dd0b2b752de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerOld(nn.Linear):\n",
    "    def __init__(self, f_in, f_out, bias=True, device=None, dtype=None,\n",
    "                 threshold=2., n_labels=10, prev_layer=None):\n",
    "        super().__init__(f_in, f_out, bias, device, dtype)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.opt = Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = threshold\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        if prev_layer != None:\n",
    "            self.prev_layer = prev_layer.to(device)\n",
    "        else:\n",
    "            self.prev_layer = prev_layer\n",
    "    \n",
    "    def forward(self, x, from_start=True):\n",
    "        if from_start and self.prev_layer != None: # Allows me to chain a bunch of layers together\n",
    "            x = self.prev_layer.forward(x)\n",
    "        \n",
    "        # normalize x so mag(x) doesn't affect goodness\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4) # L2 norm of abs(x)\n",
    "        \n",
    "        return self.relu(torch.mm(x_direction, self.weight.T) + self.bias.unsqueeze(0)) # X_dir @ W' + b\n",
    "    \n",
    "    def train(self, x, y, neg_ratio=1, train_params=True):\n",
    "        x_pos = label(x, y)\n",
    "        x_neg = get_neg(x, y, self.n_labels, neg_ratio)\n",
    "        \n",
    "        g_pos = self.forward(x_pos).pow(2).mean(1) - self.threshold\n",
    "        g_neg = self.forward(x_neg).pow(2).mean(1) - self.threshold\n",
    "        \n",
    "        loss = torch.log1p(torch.exp(\n",
    "            torch.cat([self.threshold - g_pos, g_neg - self.threshold])\n",
    "            )).mean()\n",
    "        \n",
    "        if train_params:\n",
    "            self.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            self.opt.step() # adjust weights according to Adam optimizer: gradient descent with global, local momentum\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c067b9e7-ca92-4ab2-930a-9c9fda03fa90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Layer(nn.Linear):\n",
    "    def __init__(self, f_in, f_out, bias=True, device=None, dtype=None,\n",
    "                 threshold=2., n_labels=10, prev_layer=None):\n",
    "        super().__init__(f_in, f_out, bias, device, dtype)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.opt = Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = threshold\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        if prev_layer != None:\n",
    "            self.prev_layer = prev_layer.to(device)\n",
    "        else:\n",
    "            self.prev_layer = prev_layer\n",
    "    \n",
    "    def forward(self, x, from_start=True):\n",
    "        if from_start and self.prev_layer != None: # Allows me to chain a bunch of layers together\n",
    "            x = self.prev_layer.forward(x)\n",
    "        \n",
    "        # normalize x so mag(x) doesn't affect goodness\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4) # L2 norm of abs(x)\n",
    "        \n",
    "        return self.relu(torch.mm(x_direction, self.weight.T) + self.bias.unsqueeze(0)) # X_dir @ W' + b\n",
    "    \n",
    "    def train(self, x, y, neg_ratio=1, train_params=True):\n",
    "        x_pos = label(x, y)\n",
    "        x_neg = get_neg(x, y, self.n_labels, neg_ratio)\n",
    "        \n",
    "        g_pos = self.forward(x_pos).pow(2).mean(1) - self.threshold\n",
    "        g_neg = self.forward(x_neg).pow(2).mean(1) - self.threshold\n",
    "        \n",
    "        loss = torch.log1p(torch.exp(\n",
    "            torch.cat([-g_pos, g_neg])\n",
    "            )).mean()\n",
    "        \n",
    "        if train_params:\n",
    "            self.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            self.opt.step() # adjust weights according to Adam optimizer: gradient descent with global, local momentum\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7997b764-5aa7-4943-988b-7805766dab06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerNet2():\n",
    "    def __init__(self, layer_last, device=None, num_epochs=60, n_labels=10, neg_ratio=1, log_int=1):\n",
    "        self.default_epochs = num_epochs\n",
    "        self.default_neg_ratio = neg_ratio\n",
    "        self.default_log_int = log_int\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        self.layers = [layer_last]\n",
    "        while self.layers[-1].prev_layer != None:\n",
    "            self.layers.append(self.layers[-1].prev_layer)\n",
    "        self.layers.reverse()\n",
    "\n",
    "        self.device = device\n",
    "        for i in range(len(self.layers)):\n",
    "            self.layers[i] = self.layers[i].to(device)\n",
    "    \n",
    "    def epoch(self, dl, valid=False, valid_batches=39, layer=-1, neg_ratio=None):\n",
    "        if neg_ratio == None:\n",
    "            neg_ratio = self.default_neg_ratio\n",
    "        \n",
    "        loss = 0\n",
    "        n = 0\n",
    "        train = True\n",
    "        for batch in dl:\n",
    "            if n == len(dl) - valid_batches:\n",
    "                if valid:\n",
    "                    print('Train Loss:', float(loss / n))\n",
    "                    loss = 0\n",
    "                    train = False\n",
    "                else:\n",
    "                    break\n",
    "            n += 1\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            loss += self.layers[layer].train(x, y, neg_ratio=neg_ratio, train_params=train)\n",
    "\n",
    "        if valid:\n",
    "            print('Valid Loss:', float(loss / valid_batches), '\\n')\n",
    "    \n",
    "    def train_layer(self, dl, epochs=None, layer=-1, neg_ratio=None,\n",
    "                    log_int=None, valid_batches=39):\n",
    "        if epochs == None:\n",
    "            epochs = self.default_epochs\n",
    "        if neg_ratio == None:\n",
    "            neg_ratio = self.default_neg_ratio\n",
    "        if log_int == None:\n",
    "            log_int = self.default_log_int\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            if i % log_int == 0 or i == epochs - 1:\n",
    "                valid = True\n",
    "                print('Epoch', i)\n",
    "            else:\n",
    "                valid = False\n",
    "            self.epoch(dl, valid, valid_batches, layer, neg_ratio)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        labelwise_goodness = []\n",
    "        for lb in range(self.n_labels):\n",
    "            goodness = []\n",
    "            x_lb = label(x, lb)\n",
    "            for layer in self.layers:\n",
    "                x_lb = layer.forward(x_lb, False)\n",
    "                goodness += [x_lb.pow(2).mean(1)]\n",
    "            labelwise_goodness += [sum(goodness).unsqueeze(1)]\n",
    "        labelwise_goodness = torch.cat(labelwise_goodness, 1)\n",
    "        \n",
    "        best_label = labelwise_goodness.argmax(1)\n",
    "        return best_label\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        layer = layer.to(self.device)\n",
    "        \n",
    "        assert layer.prev_layer == self.layers[-1]\n",
    "        self.layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d41410f-35a6-474c-a517-996eee93b148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerNet():\n",
    "    def __init__(self, layer_last, device=None, num_epochs=61, n_labels=10, neg_ratio=1, log_int=1):\n",
    "        self.default_epochs = num_epochs\n",
    "        self.default_neg_ratio = neg_ratio\n",
    "        self.default_log_int = log_int\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        self.layers = [layer_last]\n",
    "        while self.layers[-1].prev_layer != None:\n",
    "            self.layers.append(self.layers[-1].prev_layer)\n",
    "        self.layers.reverse()\n",
    "        if device == None:\n",
    "            self.device = self.layers[0].device\n",
    "        else:\n",
    "            self.device = device\n",
    "            for i in range(len(self.layers)):\n",
    "                self.layers[i] = self.layers[i].to(device)\n",
    "    \n",
    "    def epoch(self, dl, valid=False, valid_batches=39, layer=-1, neg_ratio=None):\n",
    "        if neg_ratio == None:\n",
    "            neg_ratio = self.default_neg_ratio\n",
    "        \n",
    "        loss = 0\n",
    "        n = 0\n",
    "        train = True\n",
    "        for batch in dl:\n",
    "            if n == len(dl) - valid_batches:\n",
    "                if valid:\n",
    "                    print('Train Loss:', float(loss / n))\n",
    "                    loss = 0\n",
    "                    train = False\n",
    "                else:\n",
    "                    break\n",
    "            n += 1\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            loss += self.layers[layer].train(x, y, neg_ratio, train)\n",
    "        \n",
    "        if valid:\n",
    "            print('Valid Loss:', float(loss / valid_batches), '\\n')\n",
    "    \n",
    "    def train_layer(self, dl, epochs=None, layer=-1, neg_ratio=None, log_int=None, valid_batches=39):\n",
    "        if epochs == None:\n",
    "            epochs = self.default_epochs\n",
    "        if neg_ratio == None:\n",
    "            neg_ratio = self.default_neg_ratio\n",
    "        if log_int == None:\n",
    "            log_int = self.default_log_int\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            if i % log_int == 0:\n",
    "                valid = True\n",
    "                print('Epoch', i)\n",
    "            else:\n",
    "                valid = False\n",
    "            self.epoch(dl, valid, valid_batches, layer, neg_ratio)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        labelwise_goodness = []\n",
    "        for l in range(self.n_labels):\n",
    "            goodness = []\n",
    "            x_l = label(x, l)\n",
    "            for layer in self.layers:\n",
    "                x_l = layer.forward(x_l, False)\n",
    "                goodness += [x_l.pow(2).mean(1)]\n",
    "            goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
    "        goodness_per_label = torch.cat(goodness_per_label, 1)\n",
    "        \n",
    "        best_label = goodness_per_label.argmax(1)\n",
    "        return best_label\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        layer = layer.to(self.device)\n",
    "        \n",
    "        assert layer.prev_layer == self.layers[-1]\n",
    "        self.layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c60ac2c-4c4e-4138-a381-907bfbf877b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_layer_1 = Layer(784, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6581170c-59a9-4f77-bf4d-92880a89b2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner = LayerNet(full_layer_1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64677f77-2d21-4370-8e40-cfcabfd4b016",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.5829491019248962\n",
      "Valid Loss: 0.5015147924423218 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.17749515175819397\n",
      "Valid Loss: 0.17058315873146057 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.1109650731086731\n",
      "Valid Loss: 0.11276230961084366 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.07938504964113235\n",
      "Valid Loss: 0.08541542291641235 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.06158198416233063\n",
      "Valid Loss: 0.0705452561378479 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.04947328940033913\n",
      "Valid Loss: 0.06238589435815811 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d76a5ce2-3a4e-4734-b8df-062c7f625e98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.7367562055587769\n",
      "Valid Loss: 0.661160945892334 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.18982559442520142\n",
      "Valid Loss: 0.1820574551820755 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.11608518660068512\n",
      "Valid Loss: 0.11534401029348373 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.08182833343744278\n",
      "Valid Loss: 0.08677788823843002 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.06258013844490051\n",
      "Valid Loss: 0.07340702414512634 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.05017593875527382\n",
      "Valid Loss: 0.06328091025352478 \n",
      "\n",
      "Epoch 60\n",
      "Train Loss: 0.042162325233221054\n",
      "Valid Loss: 0.05728112906217575 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "442948d0-978d-4152-80ff-1f4ca4763a5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.7362846732139587\n",
      "Valid Loss: 0.6617559194564819 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.18972772359848022\n",
      "Valid Loss: 0.180744931101799 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.11734099686145782\n",
      "Valid Loss: 0.11492932587862015 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.08205156773328781\n",
      "Valid Loss: 0.08769664168357849 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.06310053914785385\n",
      "Valid Loss: 0.0717085674405098 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.050495896488428116\n",
      "Valid Loss: 0.06615296751260757 \n",
      "\n",
      "Epoch 60\n",
      "Train Loss: 0.04145429655909538\n",
      "Valid Loss: 0.058082301169633865 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e468d29-8e78-4d1e-a259-77e9f2721f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_layer_1 = Layer(784, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea246ba1-6cfe-44fb-9f17-bacfa3852e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_layer_2 = Layer(2000, 2000, prev_layer=full_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b500e86-563f-4c56-9439-37e8c4d5bfe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_layer_3 = Layer(2000, 2000, prev_layer=full_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef752d48-0db3-4a20-9b67-53fe70edbf2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_layer_4 = Layer(2000, 2000, prev_layer=full_layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e710369-8115-4371-ba05-563970a250b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner = LayerNet(full_layer_1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67ef9e92-b575-4473-9f3a-cbfa5e4ff7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.7362818121910095\n",
      "Valid Loss: 0.659079909324646 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.18933932483196259\n",
      "Valid Loss: 0.18134427070617676 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.11615649610757828\n",
      "Valid Loss: 0.11297759413719177 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.08191442489624023\n",
      "Valid Loss: 0.08707794547080994 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.06281577795743942\n",
      "Valid Loss: 0.07247650623321533 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.050239045172929764\n",
      "Valid Loss: 0.06466172635555267 \n",
      "\n",
      "Epoch 60\n",
      "Train Loss: 0.041174933314323425\n",
      "Valid Loss: 0.058641720563173294 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55849fae-a8b8-496a-a12a-c14bf0f3fc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner.add_layer(full_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81ba91f3-daa7-4f0e-b38d-b5aa0bae348c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.28253650665283203\n",
      "Valid Loss: 0.1903226375579834 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.10848939418792725\n",
      "Valid Loss: 0.11301835626363754 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.09497683495283127\n",
      "Valid Loss: 0.10305686295032501 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.08763236552476883\n",
      "Valid Loss: 0.09927765280008316 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.08302408456802368\n",
      "Valid Loss: 0.09628699719905853 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.07909025996923447\n",
      "Valid Loss: 0.09407792240381241 \n",
      "\n",
      "Epoch 60\n",
      "Train Loss: 0.07703062146902084\n",
      "Valid Loss: 0.09203022718429565 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93a4567a-3569-4179-b3c5-0342cbb97423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner.add_layer(full_layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "684f7503-e71c-47c8-a903-6c84c1169dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.14118161797523499\n",
      "Valid Loss: 0.11195836216211319 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.08749993145465851\n",
      "Valid Loss: 0.09924858063459396 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.08384861797094345\n",
      "Valid Loss: 0.09779269993305206 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.081159807741642\n",
      "Valid Loss: 0.0947994589805603 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.0792660340666771\n",
      "Valid Loss: 0.09717375785112381 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.0769122987985611\n",
      "Valid Loss: 0.09235663712024689 \n",
      "\n",
      "Epoch 60\n",
      "Train Loss: 0.07484643161296844\n",
      "Valid Loss: 0.09153924137353897 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63a70e4f-1511-4783-a00e-871a507767bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner.add_layer(full_layer_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00d55499-9c6b-49b6-9389-3031af06b18b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.11338389664888382\n",
      "Valid Loss: 0.1008511483669281 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.07920875400304794\n",
      "Valid Loss: 0.09692607074975967 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.07840470224618912\n",
      "Valid Loss: 0.09510590881109238 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.07674768567085266\n",
      "Valid Loss: 0.09902723878622055 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.07668337225914001\n",
      "Valid Loss: 0.09731530398130417 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.07556270062923431\n",
      "Valid Loss: 0.09562712907791138 \n",
      "\n",
      "Epoch 60\n",
      "Train Loss: 0.07438966631889343\n",
      "Valid Loss: 0.09968055784702301 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0fceedd-9f3c-4219-9e22-832e5abe0840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.005161830357142905\n",
      "Validation Error: 0.022699511400651518\n"
     ]
    }
   ],
   "source": [
    "train_error = 0\n",
    "valid_error = 0\n",
    "i = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    error = learner2.predict(x).eq(y).float().sum().item()\n",
    "    \n",
    "    if i < len(train_valid_loader) - 39:\n",
    "        train_error += error\n",
    "    else:\n",
    "        valid_error += error\n",
    "    i += 1\n",
    "        \n",
    "x, y = (None, None)\n",
    "\n",
    "print('Training Error:', 1.0 - (train_error / 50176))\n",
    "print('Validation Error:', 1.0 - (valid_error / 9824))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "074f6f83-050f-4180-b2f4-65c1c10c5051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(learner2.layers[-1].state_dict(), 'orig_first_fully_trained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c453148b-8f3f-4ef6-b524-ea83d2c44532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_layer_1 = Layer(784, 2000)\n",
    "full_layer_2 = Layer(2000, 2000, prev_layer=full_layer_1)\n",
    "full_layer_3 = Layer(2000, 2000, prev_layer=full_layer_2)\n",
    "full_layer_4 = Layer(2000, 2000, prev_layer=full_layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28861708-8df3-4eaf-8d02-134a14bfd403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjdim\\anaconda3\\envs\\compatibility\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_layer_4.load_state_dict(torch.load('orig_first_fully_trained.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c310fb8b-17f9-45e8-9637-15a89e1b3752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner2 = LayerNet2(full_layer_4, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "654fbabc-185d-451d-a7cf-a2da9a6befb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.005161830357142905\n",
      "Validation Error: 0.022699511400651518\n"
     ]
    }
   ],
   "source": [
    "train_error = 0\n",
    "valid_error = 0\n",
    "i = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    error = learner2.predict(x).eq(y).float().sum().item()\n",
    "    \n",
    "    if i < len(train_valid_loader) - 39:\n",
    "        train_error += error\n",
    "    else:\n",
    "        valid_error += error\n",
    "    i += 1\n",
    "        \n",
    "x, y = (None, None)\n",
    "\n",
    "print('Training Error:', 1.0 - (train_error / 50176))\n",
    "print('Validation Error:', 1.0 - (valid_error / 9824))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f39fe3a-2bcb-4e82-97c6-3e0c61f82cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saved_double_threshold_net = Layer(2000, 2000, prev_layer=Layer(\n",
    "    2000, 2000, prev_layer=Layer(2000, 2000, prev_layer=Layer(784, 2000))))\n",
    "saved_double_threshold_net.load_state_dict(torch.load('orig_fully_trained_double_threshold.pth'))\n",
    "learner0 = LayerNet2(saved_double_threshold_net, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7073cb6-4d3f-4411-bf46-669e0718a5f1",
   "metadata": {},
   "source": [
    "Note: this is the same model as above. It was renamed when I realized that I had been subtracting the threshold from the goodness when assigning `g_pos` and `g_neg`, then doing so again when computing the loss (this version of `Layer` is preserved as `LayerOld`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39fbb16-3dec-4b5e-ad35-1e7fac4faea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ys = [[[],[]], [[],[]]]\n",
    "n = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    if n < len(train_valid_loader) - 39:\n",
    "        i = 0\n",
    "    else:\n",
    "        i = 1\n",
    "    n += 1\n",
    "        \n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_hat = learner0.predict(x)\n",
    "    \n",
    "    all_ys[i][0].append(y)\n",
    "    all_ys[i][1].append(y_hat)\n",
    "    \n",
    "for i in (0,1):\n",
    "    for j in (0,1):\n",
    "        if type(all_ys[i][j]) != torch.Tensor:\n",
    "            all_ys[i][j] = torch.cat(all_ys[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d7d650c-f03f-4e8c-9d56-626f2a7a498f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjdim\\anaconda3\\envs\\compatibility\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3836e52-dff7-4e65-9a86-f371e5da177c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAABxklEQVR4nO3aMUpDQRRAUSOuIp0Rgo0QxT24BmtBcAOWFpYuQbBWcAXiHmLARmKMXZbhuAHz3kfHn5v8e9pJyMDlwTyxV0opW1qp7VVfQEZAMAKAEQCMAGAEACMAGAHACAA7TT/4MDsOz++Gu3++zKZ5/nps9DknAcAIAEYAMAKAEQCMAGAEgMZ7QrYHPC0mS89O+qOmP9NJTgKAEQCMAGAEACMAGAGg8RM1Ez1Dz6af4Xe7/mdwJwHACABGADACgBEAjABgBIBqe0Ik2wMuP17D85u9g5rXwXESAIwAYAQAIwAYAcAIAEYAaGVPyGR7wOnbYunZ/X6/9nVa5yQAGAHACABGADACgBEAEE/UTPQMHb3E350cVr7MP3ASAIwAYAQAIwAYAcAIAEYAWIs9IZLtAefTeXh+OxxUvM3vOAkARgAwAoARAIwAYAQAIwCs/Z6QyfaAq/k4PL8eHNW8zo+cBAAjABgBwAgARgAwAoARADZ+T8hke0Ab/5bvJAAYAcAIAEYAMAKAEQA6/0TNRM/Qi/dZld9wEgCMAGAEACMAGAHACABGAOiVUsqqL9F1TgKAEQCMAGAEACMAGAHACABGADACwDeSey6rWQnBpAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAACG0lEQVR4nO3cvy4EQRzA8V3/Eq9Ac1zoBEFzL6BTegmNSicXrUrjKXQ60V8kIiGKK4RQ4B2IW5Vyf7Oye3ff8P20c3s3yTeTzDDZvCiKItNYTYx7AjICghEAjABgBAAjABgBwAgARgCYqvrBq5dWOH64sFV3Ln/O5eCs0udcCQBGADACgBEAjABgBAAjAFQ+J6TOAeev16VjO/OeISKuBAAjABgBwAgARgAwAkDlLWpKtA09eroJn+0ubjQ1jd/L83h8BHfjXAkARgAwAoARAIwAYAQAIwA0dk6IpM4BJ8+9cHy/1SkfrLvPT41PTJaPDb7iZytyJQAYAcAIAEYAMAKAEQCMANDcOSHaryf24uE5IMuyg8f70rHj9kr4bG3RWSB1RqnIlQBgBAAjABgBwAgARgBobota42pIPj0Tjkfb0M7dR/hsb302/vHUn6NrbL2rciUAGAHACABGADACgBEAjAAwkisvKcVnvNeP9FbjM8beQz8cP11ajn/Aq/H/gxEAjABgBAAjABgBwAgAiCsvw5Q6B1y83Ybj23NrzU2mhCsBwAgARgAwAoARAIwAYAQAxP8Txvm6m9Q5IHpNULe92cgcXAkARgAwAoARAIwAYAQAxNX4pGG+aSX67ix+Q81u/73eb/9MoZFvUS1GADACgBEAjABgBAAjAORFMcb7KMqyzJWAYAQAIwAYAcAIAEYAMAKAEQCMAPANGUFOA++7AHIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ys = torch.stack(all_ys[0], 1)\n",
    "valid_ys = torch.stack(all_ys[1], 1)\n",
    "\n",
    "train_matrix = torch.zeros(10, 10).to(device)\n",
    "valid_matrix = torch.zeros(10, 10).to(device)\n",
    "\n",
    "for i,j in train_ys:\n",
    "    train_matrix[i,j] += 1\n",
    "for i,j in valid_ys:\n",
    "    valid_matrix[i,j] += 1\n",
    "\n",
    "show_image(train_matrix)\n",
    "show_image(valid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf8e52-76d7-4b06-831e-c65706ae3d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817d8b4-4407-4227-a3eb-5d4b35cada18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10baaa56-7394-43ef-9503-8f8ae1c76964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.6792289614677429\n",
      "Valid Loss: 0.5989934206008911 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.22840581834316254\n",
      "Valid Loss: 0.21617694199085236 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.15570928156375885\n",
      "Valid Loss: 0.1535790115594864 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.12682606279850006\n",
      "Valid Loss: 0.128984734416008 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.1104545146226883\n",
      "Valid Loss: 0.11660335212945938 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.10062313079833984\n",
      "Valid Loss: 0.11265325546264648 \n",
      "\n",
      "Epoch 59\n",
      "Train Loss: 0.0950435996055603\n",
      "Valid Loss: 0.1060449555516243 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner = LayerNet2(Layer(784, 2000), device)\n",
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5374ea13-3574-4814-a7be-c30dfbe493a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.22743889689445496\n",
      "Valid Loss: 0.16252508759498596 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.11291386187076569\n",
      "Valid Loss: 0.11725227534770966 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.10263870656490326\n",
      "Valid Loss: 0.11128387600183487 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.09617090225219727\n",
      "Valid Loss: 0.10610364377498627 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.09247614443302155\n",
      "Valid Loss: 0.10631919652223587 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.08947904407978058\n",
      "Valid Loss: 0.10463357716798782 \n",
      "\n",
      "Epoch 59\n",
      "Train Loss: 0.08738861232995987\n",
      "Valid Loss: 0.10195720195770264 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.add_layer(Layer(2000, 2000, prev_layer=learner.layers[-1]))\n",
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d620278-439c-4872-a16e-8dbf2a4c7382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.1519303023815155\n",
      "Valid Loss: 0.12528231739997864 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.09692980349063873\n",
      "Valid Loss: 0.10787487030029297 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.09199530631303787\n",
      "Valid Loss: 0.10616174340248108 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.08969566226005554\n",
      "Valid Loss: 0.10500223189592361 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.0876132920384407\n",
      "Valid Loss: 0.10790468007326126 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.08461692184209824\n",
      "Valid Loss: 0.10253792256116867 \n",
      "\n",
      "Epoch 59\n",
      "Train Loss: 0.08430112898349762\n",
      "Valid Loss: 0.10280666500329971 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.add_layer(Layer(2000, 2000, prev_layer=learner.layers[-1]))\n",
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b68cd70d-275c-4c8d-bb65-880d65f0e618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 0.1269950121641159\n",
      "Valid Loss: 0.11377927660942078 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.08995765447616577\n",
      "Valid Loss: 0.11352824419736862 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.08647839725017548\n",
      "Valid Loss: 0.10862229764461517 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.0872519463300705\n",
      "Valid Loss: 0.10757683962583542 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.08581250160932541\n",
      "Valid Loss: 0.10621087998151779 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.08307977765798569\n",
      "Valid Loss: 0.10309839248657227 \n",
      "\n",
      "Epoch 59\n",
      "Train Loss: 0.08509499579668045\n",
      "Valid Loss: 0.10942553728818893 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.add_layer(Layer(2000, 2000, prev_layer=learner.layers[-1]))\n",
    "learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92ce19a3-0705-478e-be7f-1733496b7022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.010263871173469385\n",
      "Validation Error: 0.026465798045602562\n"
     ]
    }
   ],
   "source": [
    "train_error = 0\n",
    "valid_error = 0\n",
    "i = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    error = learner.predict(x).eq(y).float().sum().item()\n",
    "    \n",
    "    if i < len(train_valid_loader) - 39:\n",
    "        train_error += error\n",
    "    else:\n",
    "        valid_error += error\n",
    "    i += 1\n",
    "        \n",
    "x, y = (None, None)\n",
    "\n",
    "print('Training Error:', 1.0 - (train_error / 50176))\n",
    "print('Validation Error:', 1.0 - (valid_error / 9824))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "641b7a41-8c86-418f-af07-1dffe0dfeec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(learner.layers[-1].state_dict(), 'orig_fully_trained_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb126744-a6d8-49ba-9110-ab310a338000",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer(\n",
       "  in_features=2000, out_features=2000, bias=True\n",
       "  (relu): ReLU()\n",
       "  (prev_layer): Layer(\n",
       "    in_features=2000, out_features=2000, bias=True\n",
       "    (relu): ReLU()\n",
       "    (prev_layer): Layer(\n",
       "      in_features=2000, out_features=2000, bias=True\n",
       "      (relu): ReLU()\n",
       "      (prev_layer): Layer(\n",
       "        in_features=784, out_features=2000, bias=True\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner0.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cde2469f-4cf0-4bec-b26c-38c930b86292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saved_net = learner0.layers[-1]\n",
    "saved_net.load_state_dict(torch.load('orig_fully_trained_1.pth', weights_only=True))\n",
    "\n",
    "learner1 = LayerNet2(saved_net, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56c88fa4-da6a-4b43-8c7b-40b4fcacc7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ys = [[[],[]], [[],[]]]\n",
    "n = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    if n < len(train_valid_loader) - 39:\n",
    "        i = 0\n",
    "    else:\n",
    "        i = 1\n",
    "    n += 1\n",
    "        \n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_hat = learner1.predict(x)\n",
    "    \n",
    "    all_ys[i][0].append(y)\n",
    "    all_ys[i][1].append(y_hat)\n",
    "    \n",
    "for i in (0,1):\n",
    "    for j in (0,1):\n",
    "        if type(all_ys[i][j]) != torch.Tensor:\n",
    "            all_ys[i][j] = torch.cat(all_ys[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8f203fc-2a93-4ebc-9405-f8440087747a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAB2klEQVR4nO3cPUpDQRRAYZ+4CElnhKCFIsE9uAPBWnAJlhaWLkGwVnQF4h6CaKEEjV1wFY4b8M0d4mhO8s7XTn4GDgNzA3lNSimtaK5W570BGQHBCABGADACgBEAjABgBAAjAKyVvvDmbT+7fjXY+PVmls3D113R6zwJAEYAMAKAEQCMAGAEACMAFM8J0RxwP31sXTvo7ZV+TSd5EgCMAGAEACMAGAHACADFV9RI7hp6PP7IvrfrP4N7EgCMAGAEACMAGAHACABGAKg2J+REc8Dp+3N2/WJzp+Z2cDwJAEYAMAKAEQCMAGAEACMA/MucEInmgKPXaeva9Vav9nbKNU2Vj/EkABgBwAgARgAwAoARABBX1EjuGro7yl8Tn4Z/+DinSo+K8iQAGAHACABGADACgBEAjACwEHNCTjQHnIwn2fXLQb/mdmbiSQAwAoARAIwAYAQAIwAYAWDh54RINAecTUbZ9fP+sOZ2fuRJADACgBEAjABgBAAjABgBYOnnhEg0Bxy+fLau3W6vV9mDJwHACABGADACgBEAjADQ+Stq9A/M3DU0esplKU8CgBEAjABgBAAjABgBwAgATUqV/geqmXkSAIwAYAQAIwAYAcAIAEYAMAKAEQC+AbyTMq2gaUGhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAACMElEQVR4nO3cuy4FURhA4RnXeAUat0IjhBDxAhq1xxCVjoJOJV5DqxG1hAghJBrXAs9w4jIq5fx7Yoazwvra3zgTKzvZ+5hz8qIoikxt1dHuG5AREIwAYAQAIwAYAcAIAEYAMAJAV9UfPHocDOdrQzN17+XPOfjYrfRzrgQAIwAYAcAIAEYAMAKAEQAqnxNS54C9p9PS2eLAdPU7+odcCQBGADACgBEAjABgBIDKW9SUaBu6eX8SXtvWt8Hz/PvXNvTcnCsBwAgARgAwAoARAIwAYASAxs4JkbXh2XC+/XAYzlcG58uHqX1+ai+fmOdd5X+i4u0t/t0VuRIAjABgBAAjABgBwAgARgBo7pwQ7dcTe/HwHJBl2ertZelsa2Q8vLau8CzQ0dnIa7gSAIwAYAQAIwAYAcAIAM1tUWs8/pH39obzaBs6d/EaXns83RfOk29HR1vvj/f42opcCQBGADACgBEAjABgBAAjAPzKIy8pRav17WuPJrrD+fLNVTjfGR2LX+AXvjbWlQBgBAAjABgBwAgARgAwAgDikZeflDoH7D+fh/OF/snmbqaEKwHACABGADACgBEAjABgBADE/xNqfQy25kdoU+eA9buz0tnGSDPfculKADACgBEAjABgBAAjACAejU9eG31Ksubj6Xl3TzjfGJ4qnS1dv9R67S+uBAAjABgBwAgARgAwAoARAPKiaOPzKMqyzJWAYAQAIwAYAcAIAEYAMAKAEQCMAPAJ2EBVADRmCR8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ys = torch.stack(all_ys[0], 1)\n",
    "valid_ys = torch.stack(all_ys[1], 1)\n",
    "\n",
    "train_matrix = torch.zeros(10, 10).to(device)\n",
    "valid_matrix = torch.zeros(10, 10).to(device)\n",
    "\n",
    "for i,j in train_ys:\n",
    "    train_matrix[i,j] += 1\n",
    "for i,j in valid_ys:\n",
    "    valid_matrix[i,j] += 1\n",
    "\n",
    "show_image(train_matrix)\n",
    "show_image(valid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eab7e935-aee5-48c8-be6b-154ed57a8158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `nn.Linear.clone` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f1053-6350-4672-9841-dcca0d3178be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22efef-5fd1-42df-bdfa-8b8ef1be0cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Layer 1------\n",
      "Epoch 0\n",
      "Train Loss: 0.6784642338752747\n",
      "Valid Loss: 0.5968786478042603 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.2245180904865265\n",
      "Valid Loss: 0.21209445595741272 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.1549459844827652\n",
      "Valid Loss: 0.15133269131183624 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('------Layer 1------')\n",
    "learner = LayerNet2(Layer(784, 2000), device)\n",
    "learner.train_layer(train_valid_loader, log_int=10)\n",
    "\n",
    "print('------Layer 2------')\n",
    "learner.add_layer(Layer(2000, 2000, prev_layer=learner.layers[-1]))\n",
    "learner.train_layer(train_valid_loader, log_int=10)\n",
    "\n",
    "print('------Layer 3------')\n",
    "learner.add_layer(Layer(2000, 2000, prev_layer=learner.layers[-1]))\n",
    "learner.train_layer(train_valid_loader, log_int=10)\n",
    "\n",
    "print('------Layer 4------')\n",
    "learner.add_layer(Layer(2000, 2000, prev_layer=learner.layers[-1]))\n",
    "learner.train_layer(train_valid_loader, log_int=10)\n",
    "\n",
    "train_error = 0\n",
    "valid_error = 0\n",
    "i = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    error = learner.predict(x).eq(y).float().sum().item()\n",
    "    \n",
    "    if i < len(train_valid_loader) - 39:\n",
    "        train_error += error\n",
    "    else:\n",
    "        valid_error += error\n",
    "    i += 1\n",
    "        \n",
    "x, y = (None, None)\n",
    "\n",
    "print('Training Error:', 1.0 - (train_error / 50176))\n",
    "print('Validation Error:', 1.0 - (valid_error / 9824))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801de92-6e06-4d9d-a3f3-66786b53b02c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(learner.layers[-1].state_dict(), 'orig_fully_trained_2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33406b9-af56-47fd-9fb9-7410233d839c",
   "metadata": {},
   "source": [
    "### LVQ-Modified Training: Experimental, may not work as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cef6dc-a57f-4e1d-aaac-c5f29e9048d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQlikeLayer(Layer):\n",
    "    def __init__(self, f_in, f_out, window, bias=True, device=None,\n",
    "                 dtype=None, n_labels=10, prev_layer=None):\n",
    "        super().__init__(f_in, f_out, bias, device, dtype, None, n_labels, prev_layer)\n",
    "        self.window = window\n",
    "    \n",
    "    def train(self, x, y, neg_ratio=1, train_params=True, wind_mod=None):\n",
    "        if wind_mod != None:\n",
    "            window = self.window * wind_mod\n",
    "        else:\n",
    "            window = self.window\n",
    "        \n",
    "        g_neg = []\n",
    "        for n in range(self.n_labels):\n",
    "            yn = (y != n)\n",
    "            xn = x * yn.unsqueeze(1)\n",
    "            xn = label(xn, n) * yn.unsqueeze(1)\n",
    "            gn = self.forward(xn).pow(2).mean(1) * yn\n",
    "            g_neg.append(gn)\n",
    "        g_neg.sort(key=torch.mean, reverse=True)\n",
    "        g_neg = torch.nan_to_num(g_neg[0])\n",
    "        \n",
    "        x_pos = label(x, y)\n",
    "        x_pos = x_pos[g_neg.nonzero()].squeeze()\n",
    "        g_pos = self.forward(x_pos).pow(2).mean(1)\n",
    "        g_neg = g_neg[g_neg.nonzero()].squeeze()\n",
    "        \n",
    "        true_loss = torch.log1p(torch.exp(\n",
    "            torch.cat([-g_pos, g_neg])\n",
    "            )).mean()\n",
    "        \n",
    "        if not train_params:\n",
    "            return true_loss, len(g_pos)\n",
    "        \n",
    "        in_window = (g_pos.div(g_neg) < window)\n",
    "        in_window *= (g_neg.div(g_pos) < window)\n",
    "        \n",
    "        g_pos = torch.nan_to_num(g_pos)\n",
    "        g_neg = torch.nan_to_num(g_neg)\n",
    "        g_pos = g_pos[in_window.nonzero()].squeeze()\n",
    "        g_neg = g_neg[in_window.nonzero()].squeeze()\n",
    "        assert g_pos.shape == g_neg.shape\n",
    "        \n",
    "        if g_pos.dim() == 0:\n",
    "            g_pos = g_pos.unsqueeze(0)\n",
    "        if g_neg.dim() == 0:\n",
    "            g_neg = g_neg.unsqueeze(0)\n",
    "        \n",
    "        if g_pos.shape == 0:\n",
    "            print('No values within window')\n",
    "            return 0, 0\n",
    "            \n",
    "        func_loss = torch.log1p(torch.exp(\n",
    "            torch.cat([-g_pos, g_neg])\n",
    "            )).mean()\n",
    "        \n",
    "        self.opt.zero_grad()\n",
    "        func_loss.backward()\n",
    "        self.opt.step() # adjust weights according to Adam optimizer: gradient descent with global, local momentum\n",
    "        return func_loss, len(g_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce54baf-6c14-46e4-ab9d-ada5199f534d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerNet3():\n",
    "    def __init__(self, layer_last, device=None, num_epochs=60, n_labels=10, neg_ratio=1, log_int=1):\n",
    "        self.default_epochs = num_epochs\n",
    "        self.default_neg_ratio = neg_ratio\n",
    "        self.default_log_int = log_int\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        self.layers = [layer_last]\n",
    "        while self.layers[-1].prev_layer != None:\n",
    "            self.layers.append(self.layers[-1].prev_layer)\n",
    "        self.layers.reverse()\n",
    "\n",
    "        self.device = device\n",
    "        for i in range(len(self.layers)):\n",
    "            self.layers[i] = self.layers[i].to(device)\n",
    "    \n",
    "    def epoch(self, dl, valid=False, valid_batches=39, layer=-1, neg_ratio=None, wind_mod=0):\n",
    "        if neg_ratio == None:\n",
    "            neg_ratio = self.default_neg_ratio\n",
    "        \n",
    "        loss = 0\n",
    "        n = 0\n",
    "        train = True\n",
    "        i = 0\n",
    "        for batch in dl:\n",
    "            if n == len(dl) - valid_batches:\n",
    "                if valid:\n",
    "                    print('Train Loss:', float(loss / n))\n",
    "                    loss = 0\n",
    "                    train = False\n",
    "                else:\n",
    "                    break\n",
    "            n += 1\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            if wind_mod == 0:\n",
    "                loss += self.layers[layer].train(x, y, neg_ratio=neg_ratio, train_params=train)\n",
    "            else:\n",
    "                l, d = self.layers[layer].train(x, y, neg_ratio=neg_ratio,\n",
    "                                        train_params=train, wind_mod=wind_mod)\n",
    "                loss += l*d\n",
    "                i += d\n",
    "                \n",
    "        if valid:\n",
    "            if wind_mod == 0: # for compatibility with older layer types\n",
    "                print('Valid Loss:', float(loss / valid_batches), '\\n')\n",
    "            else:\n",
    "                print('Valid Loss:', float(loss / i), '\\n')\n",
    "    \n",
    "    def train_layer(self, dl, epochs=None, layer=-1, neg_ratio=None,\n",
    "                    log_int=None, valid_batches=39, window_func=None, w_scale=None):\n",
    "        if epochs == None:\n",
    "            epochs = self.default_epochs\n",
    "        if neg_ratio == None:\n",
    "            neg_ratio = self.default_neg_ratio\n",
    "        if log_int == None:\n",
    "            log_int = self.default_log_int\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            if i % log_int == 0 or i == epochs - 1:\n",
    "                valid = True\n",
    "                print('Epoch', i)\n",
    "            else:\n",
    "                valid = False\n",
    "                \n",
    "            if window_func in ('l', 'linear'):\n",
    "                wind_mod = w_scale * i\n",
    "            elif window_func in ('e', 'exp'):\n",
    "                wind_mod = w_scale ** i\n",
    "            else:\n",
    "                wind_mod = None\n",
    "            self.epoch(dl, valid, valid_batches, layer, neg_ratio, wind_mod)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        labelwise_goodness = []\n",
    "        for lb in range(self.n_labels):\n",
    "            goodness = []\n",
    "            x_lb = label(x, lb)\n",
    "            for layer in self.layers:\n",
    "                x_lb = layer.forward(x_lb, False)\n",
    "                goodness += [x_lb.pow(2).mean(1)]\n",
    "            labelwise_goodness += [sum(goodness).unsqueeze(1)]\n",
    "        labelwise_goodness = torch.cat(labelwise_goodness, 1)\n",
    "        \n",
    "        best_label = labelwise_goodness.argmax(1)\n",
    "        return best_label\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        layer = layer.to(self.device)\n",
    "        \n",
    "        assert layer.prev_layer == self.layers[-1]\n",
    "        self.layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494e65c-2520-46e5-bc01-19b1ee971c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 158.6410675048828\n",
      "Valid Loss: 0.11248166859149933 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 13.27021598815918\n",
      "Valid Loss: 0.4556610584259033 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: nan\n",
      "Valid Loss: 0.5295175313949585 \n",
      "\n",
      "Epoch 30\n"
     ]
    }
   ],
   "source": [
    "lvq_like_learner = LayerNet3(LVQlikeLayer(784, 2000, 2), device)\n",
    "lvq_like_learner.train_layer(train_valid_loader, log_int=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1035934-c100-4277-8a7e-f98c505e1c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_valid_loader) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d84d85-1fa1-4f98-b5d6-a72bef6800d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 160.37692260742188\n",
      "Valid Loss: 0.34702268242836 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 36.12591552734375\n",
      "Valid Loss: 0.5403748154640198 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 9.646214485168457\n",
      "Valid Loss: 0.6188862919807434 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 6.732538223266602\n",
      "Valid Loss: 0.6190103888511658 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: nan\n",
      "Valid Loss: 0.6175531148910522 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: nan\n",
      "Valid Loss: 0.6195737719535828 \n",
      "\n",
      "Epoch 59\n",
      "Train Loss: nan\n",
      "Valid Loss: 0.6218056082725525 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lvq_like_learner = LayerNet3(LVQlikeLayer(784, 2000, 2), device)\n",
    "lvq_like_learner.train_layer(train_valid_loader, log_int=10, valid_batches=118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e9c636-8a45-4d43-a75d-231d95c9f9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.07178730867346939\n",
      "Validation Error: 0.07196661237785018\n"
     ]
    }
   ],
   "source": [
    "train_error = 0\n",
    "valid_error = 0\n",
    "i = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    error = lvq_like_learner.predict(x).eq(y).float().sum().item()\n",
    "    \n",
    "    if i < len(train_valid_loader) - 39:\n",
    "        train_error += error\n",
    "    else:\n",
    "        valid_error += error\n",
    "    i += 1\n",
    "        \n",
    "x, y = (None, None)\n",
    "\n",
    "print('Training Error:', 1.0 - (train_error / 50176))\n",
    "print('Validation Error:', 1.0 - (valid_error / 9824))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b1b542-9091-4a59-9364-249fecf5b0db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ys = [[[],[]], [[],[]]]\n",
    "n = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    if n < len(train_valid_loader) - 39:\n",
    "        i = 0\n",
    "    else:\n",
    "        i = 1\n",
    "    n += 1\n",
    "        \n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_hat = lvq_like_learner.predict(x)\n",
    "    \n",
    "    all_ys[i][0].append(y)\n",
    "    all_ys[i][1].append(y_hat)\n",
    "    \n",
    "for i in (0,1):\n",
    "    for j in (0,1):\n",
    "        if type(all_ys[i][j]) != torch.Tensor:\n",
    "            all_ys[i][j] = torch.cat(all_ys[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffa1bd4d-26f2-4b1d-a71a-8a209c1706c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjdim\\anaconda3\\envs\\compatibility\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d173a9da-0b22-4b48-93ab-cf3e46013f81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAACj0lEQVR4nO3dvWoUURiA4Zl1YyALWgm6BCz8SxNIYaEiFhYGOwsbS2/Ci8hNaCMWNrYipLCyDKTwDwubTUA7WTbZbObY2sx3DptZ9y3ep/0ymSEvB/bMzm7qlFKqtFS9ZV+AjIBgBAAjABgBwAgARgAwAoARAPqlP/jq291w/npj/cwXsxC9c/G8OV3YqT80b4t+zpUAYAQAIwAYAcAIAEYAMAJA8T4htw94P9prnW0Pt0pP070F7gO64koAMAKAEQCMAGAEACMAFL9ErVfOh/PH1++1zoaf4tvJB/cn4TzNZuE8Uq+uxvN+/CdoxuO5z13KlQBgBAAjABgBwAgARgAwAkDxPiGdTOP5afst49Gd+Hbysy+jcP5mY9g+zDzSkqbxdVfBdWfV9fzH/sOVAGAEACMAGAHACABGADACQPE+ISs1cx8a7gOqqnq4335Pf3dzEB6bez8hHR+H8//BlQBgBAAjABgBwAgARgAof4ma+xRkJMW3i3OP0+xuts8GHy+Fx04e/QnnhC97ciUAGAHACABGADACgBEAjABQvk9Y4Kcgc4/TRMYPfoXz519/hvOXt67Ofe6qo6+UdSUAGAHACABGADACgBEAjADQ3SMv0WPiS/wXDbl9wIsf++F851rwZkZHXAkARgAwAoARAIwAYAQAIwAU7xN6a2vx/OKF1tns4DA89iyPr/cG8aPxuT3Kzo2tcH747mbr7MrT7/G5C7kSAIwAYAQAIwAYAcAIAMUvUZuj+FOOafp77otIJ/G3PUbf2NhMjjK/PP5Uad1fCeeXn3xund3e6+YxIFcCgBEAjABgBAAjABgBwAgAdUpLfB5FVVW5EhCMAGAEACMAGAHACABGADACgBEA/gLxbm4393o64AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAACmklEQVR4nO3dO2sUURiA4ZndXIokijaCFkYwgpUiKgbUxiIi/hMr7f0LWvkr7AWx0sbYiNoIxkILbySNuWGyu3Nsbeabw+ws+yLv0347l/ByYCacbMqUUio0Vb1p34CMgGAEACMAGAHACABGADACgBEAZnI/uP51OZw/PHNl3HuZjF4/nlejiV36RfU063OuBAAjABgBwAgARgAwAoARALLfE5reA559e1s7u3PqUv4ddW2C7wFdcSUAGAHACABGADACgBEAsh9Ry9m5cH535Xrt7Nr73+Gxby4vhPM0HATDeO9aOT8fz+fin6va3W197VyuBAAjABgBwAgARgAwAoARALLfE9LgMJ4Hz/LrF2bDYx99eRnOHyyv1g8btrSkg4N4fhj/XF29C0RcCQBGADACgBEAjABgBAAjAGS/JxRlGY/79c/raTgMjw3fA4qiuLfxqXb2ZOVceOxEt8Y3nTv3NJ2cRWMxAoARAIwAYAQAIwDkb3mZiX8dHW5LadBbWgrn0WPoiddHwmO31uJrj7a34w9EUtX+2H+4EgCMAGAEACMAGAHACABGAOhsy8s4qp2d1sf+Wo2f8+9//hjOH5893/rabo3/jxgBwAgARgAwAoARAIwA0NmWl9AU/0VD03vA8+/vwvnayYvd3UwNVwKAEQCMAGAEACMAGAHACAD5+44avpKmf/xY7Wz442d87oav8Yn2NPUWF8Nji0G8H+r26avhfOHV0drZ/q34K4RyuRIAjABgBAAjABgBwAgA+b/KHsV/5Tja3Gp9E03b6qO/DK329htOHm9fb3r03ru5WTu78eFPfO1MrgQAIwAYAcAIAEYAMAKAEQDKlKa4H0VFUbgSEIwAYAQAIwAYAcAIAEYAMAKAEQD+AsoReDaghMowAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ys = torch.stack(all_ys[0], 1)\n",
    "valid_ys = torch.stack(all_ys[1], 1)\n",
    "\n",
    "train_matrix = torch.zeros(10, 10).to(device)\n",
    "valid_matrix = torch.zeros(10, 10).to(device)\n",
    "\n",
    "for i,j in train_ys:\n",
    "    train_matrix[i,j] += 1\n",
    "for i,j in valid_ys:\n",
    "    valid_matrix[i,j] += 1\n",
    "\n",
    "show_image(train_matrix)\n",
    "show_image(valid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40dfdc3b-68ec-4d8f-b20b-4da40e7395e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss: 160.5646209716797\n",
      "Valid Loss: 0.3469107151031494 \n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 38.26777267456055\n",
      "Valid Loss: 0.5361486673355103 \n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 10.667709350585938\n",
      "Valid Loss: 0.6172273755073547 \n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 7.372105598449707\n",
      "Valid Loss: 0.6215351819992065 \n",
      "\n",
      "Epoch 40\n",
      "Train Loss: nan\n",
      "Valid Loss: 0.6201073527336121 \n",
      "\n",
      "Epoch 50\n",
      "Train Loss: nan\n",
      "Valid Loss: 0.6219157576560974 \n",
      "\n",
      "Epoch 59\n",
      "Train Loss: nan\n",
      "Valid Loss: 0.6218854188919067 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lvq_like_learner = LayerNet3(LVQlikeLayer(784, 2000, 2), device)\n",
    "lvq_like_learner.train_layer(train_valid_loader, log_int=10, valid_batches=118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "490ae957-6b8c-43d1-94d9-aac1bac7fa7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.07866310586734693\n",
      "Validation Error: 0.07379885993485347\n"
     ]
    }
   ],
   "source": [
    "train_error = 0\n",
    "valid_error = 0\n",
    "i = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    error = lvq_like_learner.predict(x).eq(y).float().sum().item()\n",
    "    \n",
    "    if i < len(train_valid_loader) - 39:\n",
    "        train_error += error\n",
    "    else:\n",
    "        valid_error += error\n",
    "    i += 1\n",
    "        \n",
    "x, y = (None, None)\n",
    "\n",
    "print('Training Error:', 1.0 - (train_error / 50176))\n",
    "print('Validation Error:', 1.0 - (valid_error / 9824))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3f740f8-a535-4450-a5b1-b0285ac05c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ys = [[[],[]], [[],[]]]\n",
    "n = 0\n",
    "\n",
    "for batch in train_valid_loader:\n",
    "    if n < len(train_valid_loader) - 39:\n",
    "        i = 0\n",
    "    else:\n",
    "        i = 1\n",
    "    n += 1\n",
    "        \n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_hat = lvq_like_learner.predict(x)\n",
    "    \n",
    "    all_ys[i][0].append(y)\n",
    "    all_ys[i][1].append(y_hat)\n",
    "    \n",
    "for i in (0,1):\n",
    "    for j in (0,1):\n",
    "        if type(all_ys[i][j]) != torch.Tensor:\n",
    "            all_ys[i][j] = torch.cat(all_ys[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fd032d7-35c8-41ef-aad1-d3596b134fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c91a179e-8c82-4f0b-bc80-65946e6933c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAACkklEQVR4nO3dvWpUQRiA4TmbXY1oq0hAFsWghggBQVKKIGJpI3oZXkkuwU5Bi9QiiKVi4w9EJaLYxEIsolXcn2MvzDeT3U3yRt6n/fZkF94MnJk9IU3btm3Sgeoc9AeQERCMAGAEACMAGAHACABGADACQLf2hQ83r4bzBxf6U3+YPdE08XwPDwyejZ9Uvc6VAGAEACMAGAHACABGADACQPU+obQPeLr1Jju7ubBS+zazdwi+OHQlABgBwAgARgAwAoARAKpvUZvekXB+69xqdrb69nd47cuV+GeHSreghaPsptuLf/zgz24/0a65EgCMAGAEACMAGAHACABGAKjeJ5S0w2F29urKsfDa6++2w/nzy8ezs9L+pXSf345G4Xw/uBIAjABgBAAjABgBwAgARgCo3icUz9Wjc/vCmX+0D0gppdsbP7Kz9aWT4bXFR+PH7hOUjIBgBAAjABgBwAgAM3vkJbXj/Cg45k4ppdSZC8fry6ezs96LU+G1wxs/w3k7HITz/Xiq25UAYAQAIwAYAcAIAEYAMAJA/VF26dGQYJ9QNMVx8uDa93B+7+NWOH90cWHi954VVwKAEQCMAGAEACMAGAHACAD1j8aX7uXD7wQKe4hp/gy2cG1pH3D/84dwvnb+UjifBVcCgBEAjABgBAAjABgBwAgA1fuEzvx8OG/OnsnORp++xNd24+eOmrnJf1dKzzytLS6F82+Pl7Oz/t2NiT7Tv1wJAEYAMAKAEQCMAGAEgOpb1PHOTjhvNr8GF8fH4KWHzzsn8n/dOdr+FV9ceO/SrXf/zvvsbPH10fi9K7kSAIwAYAQAIwAYAcAIAEYAaNr2EPznn/+cKwHACABGADACgBEAjABgBAAjABgB4C/BtnPxsKPG+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAClUlEQVR4nO3csWpTURyA8ZOkqbVTFxeJqKUK6lIUoU6CDsVn8BHcdHfo7ugjdPIJxMnNSUUXMaWIlOLgokgxsbnXB5DzP8ck0o/4/dZ/bm/Kx4F7kpvbadu2TTpR3ZN+AzICghEAjABgBAAjABgBwAgARgBYqn3h+8+DcP7wwq2Z38yiedE8q3qdKwHACABGADACgBEAjABgBIDqfUJpH/D88G12tn12s/Y0/yVXAoARAIwAYAQAIwAYAaD6ErXTXw7n99a3srP7H/bCY3evnKt9G38q3bvW6cTj5fj/asfj6c9dyZUAYAQAIwAYAcAIAEYAMAJA9T4htU04bsaT7Gz36vnw2EfDd+H8yca17Ky7uhq/r6OjcB7uA1KK9wKFPUgtVwKAEQCMAGAEACMAGAHACADV+4T2+Dh+QbeXnzX5PURK8T4gpZQe77/OznbWr4fHFs3ynYDfJywOIwAYAcAIAEYAMAJA9SVqd2UlnDfjX/lh6baTXnB5m1La2biZnQ1enQ6PPbwTfwRf+ii7eGk+B64EACMAGAHACABGADACgBEAqvcJzWg0/VkKH/nOci1+sPUjnD8YfgznTy9dnvrc8+JKADACgBEAjABgBAAjABgBoP7W+JJO0LONb3n5l0r7gOjpNCkVnlDjrfGLwwgARgAwAoARAIwAYASA+kftLPXDefdi/nE5k+H+TH87PLYf/wvNz/h7kO3BjXB+6uWZ7Gx892t4bC1XAoARAIwAYAQAIwAYAeAvfr0Z3PqeUprsfQoOLt3yEv/t3tpa/rzfvofHln45WnpKzOj2l+xs80186lquBAAjABgBwAgARgAwAoARADptO6dHlWhqrgQAIwAYAcAIAEYAMAKAEQCMAGAEgN/9eXYOshrPQgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ys = torch.stack(all_ys[0], 1)\n",
    "valid_ys = torch.stack(all_ys[1], 1)\n",
    "\n",
    "train_matrix = torch.zeros(10, 10).to(device)\n",
    "valid_matrix = torch.zeros(10, 10).to(device)\n",
    "\n",
    "for i,j in train_ys:\n",
    "    train_matrix[i,j] += 1\n",
    "for i,j in valid_ys:\n",
    "    valid_matrix[i,j] += 1\n",
    "\n",
    "show_image(train_matrix)\n",
    "show_image(valid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630de4d-7341-4512-9283-f5905668b859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5533c55-6d28-4108-90cc-dfd01b0800de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee7d70-ad81-4ed7-b07f-b1c7f8325081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb39cc-22ab-4240-b172-a556ecae8bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7358e2-effe-4e3c-8d73-ff21d1c95efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mini_path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0acdb245-8c24-42ed-9826-69eeb5ed59cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "                    transforms.Lambda(Image.open),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                    transforms.Lambda(torch.flatten)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5e707-ebdd-4147-a3c2-4e4a24b8dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train = get_image_files(mini_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35957103-1cc3-467d-9af1-f14e8fd337be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mget_image_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mget_image_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"Get image files in `path` recursively, only in `folders`, if specified.\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mget_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_extensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfolders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\sjdim\\anaconda3\\envs\\compatibility\\lib\\site-packages\\fastai\\data\\transforms.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_image_files??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bd0fb-eccb-4105-8475-409776f5170a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compatibility",
   "language": "python",
   "name": "compatibility"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
