{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "777c16a9-7f69-4757-a4d2-c0d8a2688ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from torchvision import transforms as vis_tfms\n",
    "import random\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57431cf7-7eeb-434b-8629-e2d02a542c46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4de35c1-fc04-40db-afc2-ceef7577373a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d196389b-ee3a-463a-8c21-8cefb0cc8fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_tf = vis_tfms.Compose([vis_tfms.ToTensor(), vis_tfms.Normalize((0.1307), (0.3081)),\n",
    "                            vis_tfms.Lambda(torch.flatten)])\n",
    "\n",
    "orig_train_kwargs = {'batch_size': 50000}\n",
    "orig_test_kwargs = {'batch_size': 10000}\n",
    "if device == 'cuda':\n",
    "    orig_cuda_kwargs = {'num_workers': 1, 'shuffle': True, 'pin_memory': pin_memory}\n",
    "    orig_train_kwargs.update(orig_cuda_kwargs)\n",
    "    orig_test_kwargs.update(orig_cuda_kwargs)\n",
    "\n",
    "orig_train_loader = torch.utils.data.DataLoader(\n",
    "    MNIST('./data/', train=True, download=True, transform=orig_tf), **orig_train_kwargs\n",
    ")\n",
    "\n",
    "orig_test_loader = torch.utils.data.DataLoader( # may be unnecessary\n",
    "    MNIST('./data/', train=False, download=True, transform=orig_tf), **orig_test_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9744cc1-5a76-493c-9142-8e8f7ba85ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label(x, y, n_labels=10):\n",
    "    out = x.clone()\n",
    "    out[:, :n_labels] *= 0.0\n",
    "    out[range(x.shape[0]), y] = x.max()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fd0fa3f-99a5-4a94-acba-6a4bc20ea93e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neg(x, y, n_labels=10, ratio=1): # constructed myself\n",
    "    labels = []\n",
    "    for n in range(n_labels):\n",
    "        labels.append(n)\n",
    "        \n",
    "    y_neg = []\n",
    "    for n in range(ratio):\n",
    "        y_neg.append(torch.zeros_like(y))\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        labels_ = labels.copy()\n",
    "        labels_.remove(y[i])\n",
    "        negs = random.sample(labels_, k=ratio)\n",
    "        for n in range(len(negs)):\n",
    "            y_neg[n][i] = negs[n]\n",
    "            \n",
    "    x_neg = []\n",
    "    for yn in y_neg:\n",
    "        x_neg.append(label(x, yn, n_labels))\n",
    "    x_neg = torch.cat(x_neg)\n",
    "    return x_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4930837d-4c6f-4c44-b942-656991350b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a, b = orig_train_loader\n",
    "x, y = a\n",
    "x, y = x.to(device), y.to(device)\n",
    "\n",
    "x_val, y_val = b\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918740fe-14d3-4f98-ba09-0d41018c592e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ec5ce7-22bb-4b11-bcf3-b776e774209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(nn.Linear):\n",
    "    def __init__(self, f_in, f_out, bias=True, device=None, dtype=None,\n",
    "                threshold=2., num_epochs=60, bs=256, n_labels=10):\n",
    "        super().__init__(f_in, f_out, bias, device, dtype)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.opt = Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = threshold\n",
    "        self.num_epochs = num_epochs\n",
    "        self.bs = bs\n",
    "        self.n_labels = n_labels\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4) # not sure what the point of this is, but it looks kind of like LVQ\n",
    "        # norm yields L2 norm of abs(x): sum(abs(x)**2)**(1/2); 2 can be replaced by any number using 1st arg\n",
    "        # using 'fro' as first arg gives L2 norm of x\n",
    "        # using 'nuc' gives nuclear norm of x: sum(root2(e_i)) for eigenvalues E of X' @ X or X @ X'\n",
    "        \n",
    "        return self.relu(torch.mm(x_direction, self.weight.T) + self.bias.unsqueeze(0)) # X_dir @ W' + b\n",
    "    \n",
    "    def train_one_batch(self, x, y):\n",
    "        x_pos = label(x, y)\n",
    "        x_neg = get_neg(x, y)\n",
    "        \n",
    "        g_pos = self.forward(x_pos).pow(2).mean(1) - self.threshold\n",
    "        g_neg = self.forward(x_neg).pow(2).mean(1) - self.threshold\n",
    "        \n",
    "        loss = torch.log1p\n",
    "    \n",
    "    def train(self, x_pos, x_neg):\n",
    "        for i in range(self.num_epochs):\n",
    "            # for each image, obtain average of squared activations\n",
    "            g_pos = self.forward(x_pos).pow(2).mean(1)\n",
    "            g_neg = self.forward(x_neg).pow(2).mean(1)\n",
    "            \n",
    "            # for each image, loss = ln(1 + e^(wrongness))\n",
    "            # for negative wrongness = positive/negative(goodness - threshold)\n",
    "            loss = torch.log1p(torch.exp(\n",
    "                torch.cat([self.threshold - g_pos, g_neg - self.threshold])\n",
    "            )).mean()\n",
    "            \n",
    "            self.opt.zero_grad() # reset gradient to 0\n",
    "            loss.backward() # calculate gradient - not backpropagation because nothing to propagate to\n",
    "            self.opt.step() # adjust weights according to Adam optimizer: gradient descent with global, local momentum\n",
    "            if i % log_interval == 0:\n",
    "                print('Loss: ', loss.item())\n",
    "                \n",
    "        self.opt.zero_grad() # to save memory        \n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach() # send to next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec4016d7-ab1e-40d9-911a-b6ee85f2c2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca61af-8b8e-4893-a788-e9aa902ad752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compatibility",
   "language": "python",
   "name": "compatibility"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
